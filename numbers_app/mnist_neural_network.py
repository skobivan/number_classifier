# -*- coding: utf-8 -*-
"""MNIST_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qp5wmDDfRcQ8SV1yonGp4IVOf33jL0Dk
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import random as rand


class MLP(nn.Module):
  def __init__(self, input_dim, hidden_dims, out_dim):
    super(MLP, self).__init__()
    self.fc1 = nn.Linear(input_dim, hidden_dims[0])
    self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])
    self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])
    self.fc4 = nn.Linear(hidden_dims[2], hidden_dims[3])
    self.fc5 = nn.Linear(hidden_dims[3], out_dim)

  def forward(self, x_in):
    intermediate = F.relu(self.fc1(x_in))
    intermediate = F.relu(self.fc2(intermediate))
    intermediate = F.relu(self.fc3(intermediate))
    intermediate = F.relu(self.fc4(intermediate))

    output = torch.sigmoid(self.fc5(intermediate))
    return output

def train_and_save(file_name, iterations):
  from keras.datasets import mnist
  (x_train, y_train), (x_test, y_test) = mnist.load_data()

  images = x_train[0:1000].reshape(1000, 28*28)/255
  labels = y_train[0:1000]

  one_hot_labels = np.zeros((len(labels), 10))

  for i, l in enumerate(labels):
    one_hot_labels[i][l] = 1
  labels = one_hot_labels

  hidden_size, pix_per_img, num_labels = \
                                            (40, 784, 10)

  device = torch.device("cpu")

  classifier = MLP(pix_per_img, 364, 10)
  classifier = classifier.to(device)

  loss_func = nn.BCELoss()
  optimizer = optim.Adam(classifier.parameters())

  for iter in range(iterations):
    run_loss = 0.0
    classifier.train()

    for i in range(images.shape[0]):
      optimizer.zero_grad()

      y_pred = classifier(x_in = torch.Tensor(images[i]))

      loss = loss_func(y_pred, torch.Tensor(labels[i]))

      run_loss += loss

      loss.backward()

      optimizer.step()

      if i+1 == images.shape[0]:
        k = rand.randint(0, images.shape[0]-1)
        y_pred = classifier(x_in = torch.Tensor(images[k]))
        loss = loss_func(y_pred, torch.Tensor(labels[k]))
        print("Iteration:", iter, "Run loss:", run_loss, "Pred:", torch.argmax(y_pred), "Target:", torch.argmax(torch.Tensor(labels[k])), 'Loss:', loss)

    torch.save(classifier.state_dict(), file_name)


# train_and_save('numbers_data', 20)

class ImgClassifier:
  def __init__(self, load_path):
    self.model = MLP(784, [512, 256, 128, 64], 10)
    try:
      self.model.load_state_dict(torch.load(load_path))
      self.model.eval()
    except:
      print('LOAD_ERROR')
      raise

  def predicate(self, img):
    return torch.argmax(self.model(x_in = torch.Tensor(img)))

  def test(self):
    from keras.datasets import mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    test_images = x_test.reshape(len(x_test), 28 * 28) / 255
    test_labels = np.zeros((len(y_test), 10))
    loss_func = nn.BCELoss()
    for i, l in enumerate(y_test):
      test_labels[i][l] = 1
    error = 0.0
    print(test_images.shape[0])
    for i in range(test_images.shape[0]):
        y_pred = self.model(x_in = torch.Tensor(test_images[i]))
        loss = loss_func(y_pred, torch.Tensor(test_labels[i]))
        error += loss
    print("Loss:", error/test_images.shape[0])

# classifier = ImgClassifier('test1')

# classifier.test()

